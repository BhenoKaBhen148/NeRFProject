## get_rays



`[(i-K[0][2])/K[0][0], -(j-K[1][2])/K[1][1], -np.ones_like(i)]`

- 射线方向

    ![](https://pic4.zhimg.com/80/v2-7e833f6889faf77538641b6f887e1f4b_720w.webp)

    这是在相机坐标系下，像素点的坐标的x和y坐标是2D图像坐标 (i, j) 减去光心坐标 (cx,cy)，然后z坐标其实就是焦距。

    射线的方向向量是 $(i-c_x, j-c_y, f) - (0, 0, 0) = (i-c_x, j-c_y, f)$

    因为是向量，我们可以把整个向量除以焦距f归一化z坐标，得到 $(\frac{i-c_x}{f}, \frac{j-c_y}{f}, 1)$ 。

- 不同的相机坐标系转化

    这里的c2w已经是NeRF的RUB方向，所以我们需要RUB的相机坐标系。

    而经过meshgrid构建出来的2D坐标系(左上角是原点，向右是x轴，向下是y轴)和射线方向打向场景是正的，刚好是COLMAP的相机坐标系统RDF。

    则，y与z轴需要进行相反数转换。

- 描述一个光线需要两个量，起点和方向。
  - 起点：相机坐标系下，从原点发出光线，则光线的起点就是(0,0,0)；经过旋转，还是(0,0,0)，只需要加上**世界坐标下看相机坐标原点**的平移量，(t_x, t_y, t_z)。
  - 方向：我们现在有在相机坐标系下的从相机原点出发的向量`dirs`（也可以看作在相机坐标系下的物体的点），`dirs`与`c2w`的 $R$ 运算就得到了在世界坐标系的向量`rays_d`，`rays_o`只是原点之间的平移量。也就是说，`rays_d`和`rays_o`并不是光线的方向和起点，只是个半成品。

    `view_ray =  ray_o + ray_d`才是黄色的O'C.

> 为什么光线取反方向

> 用R,t去解答平均中心位姿